{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "we54z92Jc_Tk"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BHglOyGac_Tt"
   },
   "outputs": [],
   "source": [
    "def load_file(fileName):\n",
    "    dataset = pd.read_csv(fileName, header=0, sep=\",\", encoding=\"unicode_escape\")\n",
    "    return dataset\n",
    "  \n",
    "dataPath = 'data/TextClassification_Data.csv'\n",
    "data = load_file(dataPath)\n",
    "#data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8CRGLzGqc_Tx"
   },
   "outputs": [],
   "source": [
    "# preprocess creates the term frequency matrix for the review data set\n",
    "def preprocess(data):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    data = count_vectorizer.fit_transform(data)\n",
    "    \n",
    "    #tfidf_data = TfidfTransformer(use_idf=False).fit_transform(data)\n",
    "    #print(data[0].toarray())\n",
    "    #print(count_vectorizer.vocabulary_[i[0][1]])\n",
    "    return data, count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "DxIM_WAjaDJr",
    "outputId": "759d777a-d628-4a28-f7c2-a8a0d59c8289"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(data.toarray().shape)\\nfor i in range(data.shape[0]):\\n    print(np.where(data[i].toarray() > 0)[1])\\n    print(data[i].toarray()[np.where(data[i].toarray() > 0)[1]])\\n    break;\\n'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(data.toarray().shape)\n",
    "for i in range(data.shape[0]):\n",
    "    print(np.where(data[i].toarray() > 0)[1])\n",
    "    print(data[i].toarray()[np.where(data[i].toarray() > 0)[1]])\n",
    "    break;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0Be6c-Vc_T0"
   },
   "outputs": [],
   "source": [
    "def learn_model(data, target):\n",
    "    #Your custom implementation of NaiveBayes classifier will go here.\n",
    "    classes, counts = np.unique(np.array(target), return_counts=True)\n",
    "    classCount = dict([(i, j) for i,j in zip(classes, counts)])\n",
    "    sumClass = sum(counts)\n",
    "    classifier = dict()\n",
    "    \n",
    "    seenWordsEachClass = dict([(i, set()) for i in classes])\n",
    "    #Your custom implementation of NaiveBayes classifier will go here.\n",
    "    for i, clas in zip(data, target): \n",
    "        tempdata = i.toarray()[0]\n",
    "        nonZeros = np.where(tempdata > 0)[0] #basically index of words present in the current sentence\n",
    "                                              #(index here is with respect to bag of words)\n",
    "        for j in nonZeros:\n",
    "            if j not in seenWordsEachClass[clas]:\n",
    "                seenWordsEachClass[clas].add(j)\n",
    "            if j not in classifier:\n",
    "                classifier[j] = dict([(cl, [0, count]) for cl, count in classCount.items()])\n",
    "            classifier[j][clas][0] += tempdata[j]  \n",
    "    seenWords = set()\n",
    "    #Laplacian smoothing:n\n",
    "    for word in range(len(data[0].toarray()[0])):\n",
    "        if word in classifier:\n",
    "            if word not in seenWords:\n",
    "                seenWords.add(word)\n",
    "                for prob in classifier[word]:  \n",
    "                      classifier[word][prob][0] += 1\n",
    "        else:\n",
    "            classifier[word] = dict([(cl, [1, count]) for cl, count in classCount.items()])\n",
    "\n",
    "    for j in classifier: \n",
    "        for i in classifier[j]:\n",
    "            classifier[j][i][0] /= (classifier[j][i][1] + len(seenWordsEachClass[i]))\n",
    "            classifier[j][i][1] /= sumClass\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rDF-JqpYc_T4"
   },
   "outputs": [],
   "source": [
    "def classify(classifier, testdata):\n",
    "    predicted_val=[]\n",
    "    classProbs = dict([(i, classifier[0][i][1]) for i in classifier[0]])\n",
    "    #Your code to classify test data using the learned model will go here\n",
    "    probClassesGivenSentence = dict([(j, 1) for j in classifier[0]])\n",
    "    for i in testdata:\n",
    "        probClassesGivenSentence = dict([(j, 1) for j in classifier[0]])\n",
    "        arr = i.toarray()[0]\n",
    "        nonZeros = np.where(arr > 0)[0]\n",
    "        probs = dict([(j, classifier[j]) for j in nonZeros])\n",
    "        for x in probs:\n",
    "            for y in probs[x]:               \n",
    "                probClassesGivenSentence[y] *= probs[x][y][0]\n",
    "        probClassesGivenSentence = dict([(y, probClassesGivenSentence[y]*classProbs[y]) for y in probClassesGivenSentence])\n",
    "        prediction = max(probClassesGivenSentence, key=lambda k: probClassesGivenSentence[k]) \n",
    "        predicted_val.append(prediction)   \n",
    "   \n",
    "    return predicted_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nDWDviZc_T7"
   },
   "outputs": [],
   "source": [
    "def evaluate(actual_class, predicted_class):\n",
    "    #Your code to evaluate the model will go here. The code will print overall model's accuracy and precision \n",
    "    #and recall for each class label.\n",
    "    count = 0\n",
    "    for i in range(len(actual_class)):\n",
    "        if actual_class[i] == predicted_class[i]:\n",
    "            count += 1\n",
    "    accuracy = count*100/len(actual_class)\n",
    "    \n",
    "    print(\"The accuracy score is :\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "mLAxTL8tc_T_",
    "outputId": "c1133ea9-4ef0-48f6-99f4-3ff90f825bee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data.....\n",
      "preprocessing data.....\n",
      "Learning model.....\n",
      "Classifying test data......\n",
      "Evaluating results.....\n",
      "The accuracy score is : 39.114874301675975\n"
     ]
    }
   ],
   "source": [
    "features = [\"SUMMARY\", \"categories\", \"sub_categories\"]\n",
    "\n",
    "print(\"Loading data.....\")\n",
    "dataset = load_file(dataPath)\n",
    "data, target = dataset[features[0]].fillna(\" \"), dataset[features[1]]\n",
    "\n",
    "print(\"preprocessing data.....\")\n",
    "word_vectors, cv = preprocess(data)\n",
    "#print(cv.get_feature_names()[2415], cv.get_feature_names()[7090])\n",
    "trainingX,testX,trainingY,testY = train_test_split(word_vectors,target,test_size=0.4,random_state=43)\n",
    "#print(trainingX.shape,testX.shape,trainingY.shape,testY.shape)\n",
    "print(\"Learning model.....\")\n",
    "model = learn_model(trainingX,trainingY)\n",
    "testY = testY.tolist()\n",
    "print(\"Classifying test data......\")      \n",
    "predictedY = classify(model, testX)\n",
    "classes, counts = np.unique(np.array(predictedY), return_counts=True)\n",
    "print(\"Evaluating results.....\")\n",
    "evaluate(testY,predictedY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D-eJf1I0c_UE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NaiveBayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
