{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "NaiveBayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9sVL7dmdATV",
        "colab_type": "code",
        "outputId": "eb2a73d2-404f-4d5d-9484-6787ec4c6a7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cawB9ceNdRyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/aiAssignment2/assignment2/q1a/NaiveBayesClassifier'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we54z92Jc_Tk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHglOyGac_Tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_file(fileName):\n",
        "    dataset = pd.read_csv(fileName, header=0, sep=\",\", encoding=\"unicode_escape\")\n",
        "    return dataset\n",
        "  \n",
        "dataPath = path+'/data/TextClassification_Data.csv'\n",
        "data = load_file(dataPath)\n",
        "#data.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CRGLzGqc_Tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocess creates the term frequency matrix for the review data set\n",
        "def preprocess(data):\n",
        "    count_vectorizer = CountVectorizer(stop_words= 'english')\n",
        "    data = count_vectorizer.fit_transform(data)\n",
        "    \n",
        "    #tfidf_data = TfidfTransformer(use_idf=False).fit_transform(data)\n",
        "    #print(data[0].toarray())\n",
        "    #print(count_vectorizer.vocabulary_[i[0][1]])\n",
        "    return data, count_vectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxIM_WAjaDJr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "759d777a-d628-4a28-f7c2-a8a0d59c8289"
      },
      "source": [
        "'''\n",
        "print(data.toarray().shape)\n",
        "for i in range(data.shape[0]):\n",
        "    print(np.where(data[i].toarray() > 0)[1])\n",
        "    print(data[i].toarray()[np.where(data[i].toarray() > 0)[1]])\n",
        "    break;\n",
        "'''"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(data.toarray().shape)\\nfor i in range(data.shape[0]):\\n    print(np.where(data[i].toarray() > 0)[1])\\n    print(data[i].toarray()[np.where(data[i].toarray() > 0)[1]])\\n    break;\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0Be6c-Vc_T0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def learn_model(data, target):\n",
        "    #Your custom implementation of NaiveBayes classifier will go here.\n",
        "    classes, counts = np.unique(np.array(target), return_counts=True)\n",
        "    classCount = dict([(i, j) for i,j in zip(classes, counts)])\n",
        "    classifier = dict()\n",
        "    \n",
        "    seenWordsEachClass = dict([(i, set()) for i in classes])\n",
        "    #Your custom implementation of NaiveBayes classifier will go here.\n",
        "    for i, clas in zip(data, target): \n",
        "        tempdata = i.toarray()[0]\n",
        "        nonZeros = np.where(tempdata > 0)[0] #basically index of words present in the current sentence\n",
        "                                              #(index here is with respect to bag of words)\n",
        "        for j in nonZeros:\n",
        "            if j not in seenWordsEachClass[clas]:\n",
        "                seenWordsEachClass[clas].add(j)\n",
        "            if j not in classifier:\n",
        "                classifier[j] = dict([(cl, 0) for cl in classes])\n",
        "            classifier[j][clas] += tempdata[j]  \n",
        "    seenWords = set()    \n",
        "    c = 0\n",
        "    #Laplacian smoothing:\n",
        "\n",
        "    for word in range(len(data[0].toarray()[0])):\n",
        "        if word in classifier:\n",
        "            if word not in seenWords:\n",
        "                seenWords.add(word)\n",
        "                for prob in classifier[word]:  \n",
        "                      classifier[word][prob] += 1\n",
        "        else:\n",
        "            c+=1\n",
        "            classifier[word] = dict([(cl, 1) for cl in classes])\n",
        "\n",
        "    for j in classifier: \n",
        "        for i in classifier[j]:\n",
        "          classifier[j][i] /= (classCount[i] + 2)\n",
        "    return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDF-JqpYc_T4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify(classifier, testdata):\n",
        "    predicted_val=[]\n",
        "        \n",
        "    #Your code to classify test data using the learned model will go here\n",
        "    for i in testdata:\n",
        "        probClassesGivenSentence = dict([(j, 1) for j in classifier[0]])\n",
        "        arr = i.toarray()[0]\n",
        "        nonZeros = np.where(arr > 0)[0]\n",
        "        probs = dict([(j, classifier[j]) for j in nonZeros])\n",
        "        print(probs)\n",
        "        break\n",
        "        for x in probs:\n",
        "            for y in probs[x]:               \n",
        "                probClassesGivenSentence[y] *= probs[x][y]\n",
        "        prediction = max(probClassesGivenSentence, key=lambda k: probClassesGivenSentence[k]) \n",
        "        predicted_val.append(prediction)   \n",
        "   \n",
        "    return predicted_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nDWDviZc_T7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(actual_class, predicted_class):\n",
        "        \n",
        "    accuracy = -1    \n",
        "    #Your code to evaluate the model will go here. The code will print overall model's accuracy and precision \n",
        "    #and recall for each class label.\n",
        "    \n",
        "    \n",
        "    print(\"The accuracy score is :\",accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLAxTL8tc_T_",
        "colab_type": "code",
        "outputId": "c1133ea9-4ef0-48f6-99f4-3ff90f825bee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "features = [\"SUMMARY\", \"categories\", \"sub_categories\"]\n",
        "\n",
        "print(\"Loading data.....\")\n",
        "dataset = load_file(dataPath)\n",
        "data, target = dataset[features[0]].fillna(\" \"), dataset[features[1]]\n",
        "\n",
        "print(\"preprocessing data.....\")\n",
        "word_vectors, cv = preprocess(data)\n",
        "#print(cv.get_feature_names()[2415], cv.get_feature_names()[7090])\n",
        "trainingX,testX,trainingY,testY = train_test_split(word_vectors,target,test_size=0.4,random_state=43)\n",
        "\n",
        "#print(trainingX.shape,testX.shape,trainingY.shape,testY.shape)\n",
        "print(\"Learning model.....\")\n",
        "model = learn_model(trainingX,trainingY)\n",
        "\n",
        "print(\"Classifying test data......\")      \n",
        "predictedY = classify(model, testX)\n",
        "print(predictedY)\n",
        "classes, counts = np.unique(np.array(predictedY), return_counts=True)\n",
        "print(classes, counts)\n",
        "print(\"Evaluating results.....\")\n",
        "#evaluate(testY,predictedY)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data.....\n",
            "preprocessing data.....\n",
            "Learning model.....\n",
            "{'APPOINTMENTS': 325, 'ASK_A_DOCTOR': 6, 'JUNK': 1, 'LAB': 1, 'MISCELLANEOUS': 6, 'PRESCRIPTION': 5}\n",
            "{'APPOINTMENTS': 1, 'ASK_A_DOCTOR': 3, 'JUNK': 1, 'LAB': 1, 'MISCELLANEOUS': 1, 'PRESCRIPTION': 4}\n",
            "{'APPOINTMENTS': 1, 'ASK_A_DOCTOR': 1, 'JUNK': 1, 'LAB': 1, 'MISCELLANEOUS': 1, 'PRESCRIPTION': 2}\n",
            "{'APPOINTMENTS': 1, 'ASK_A_DOCTOR': 1, 'JUNK': 1, 'LAB': 1, 'MISCELLANEOUS': 2, 'PRESCRIPTION': 1}\n",
            "{'APPOINTMENTS': 1, 'ASK_A_DOCTOR': 1, 'JUNK': 1, 'LAB': 1, 'MISCELLANEOUS': 1, 'PRESCRIPTION': 2}\n",
            "{'APPOINTMENTS': 1, 'ASK_A_DOCTOR': 2, 'JUNK': 1, 'LAB': 1, 'MISCELLANEOUS': 3, 'PRESCRIPTION': 1}\n",
            "{'APPOINTMENTS': 1, 'ASK_A_DOCTOR': 1, 'JUNK': 1, 'LAB': 1, 'MISCELLANEOUS': 1, 'PRESCRIPTION': 1}\n",
            "{'APPOINTMENTS': 1, 'ASK_A_DOCTOR': 2, 'JUNK': 1, 'LAB': 1, 'MISCELLANEOUS': 1, 'PRESCRIPTION': 1}\n",
            "{'APPOINTMENTS': 1, 'ASK_A_DOCTOR': 1, 'JUNK': 1, 'LAB': 1, 'MISCELLANEOUS': 1, 'PRESCRIPTION': 1}\n",
            "{'APPOINTMENTS': 1, 'ASK_A_DOCTOR': 1, 'JUNK': 1, 'LAB': 1, 'MISCELLANEOUS': 3, 'PRESCRIPTION': 1}\n",
            "{'APPOINTMENTS': 0.03932244404113733, 'ASK_A_DOCTOR': 0.0008378718056137411, 'JUNK': 0.07692307692307693, 'LAB': 0.00038550501156515033, 'MISCELLANEOUS': 0.0008231581835642749, 'PRESCRIPTION': 0.0005519982336056525}\n",
            "{'APPOINTMENTS': 0.00012099213551119177, 'ASK_A_DOCTOR': 0.00041893590280687055, 'JUNK': 0.07692307692307693, 'LAB': 0.00038550501156515033, 'MISCELLANEOUS': 0.00013719303059404582, 'PRESCRIPTION': 0.00044159858688452196}\n",
            "{'APPOINTMENTS': 0.00012099213551119177, 'ASK_A_DOCTOR': 0.00013964530093562352, 'JUNK': 0.07692307692307693, 'LAB': 0.00038550501156515033, 'MISCELLANEOUS': 0.00013719303059404582, 'PRESCRIPTION': 0.00022079929344226098}\n",
            "{'APPOINTMENTS': 0.00012099213551119177, 'ASK_A_DOCTOR': 0.00013964530093562352, 'JUNK': 0.07692307692307693, 'LAB': 0.00038550501156515033, 'MISCELLANEOUS': 0.00027438606118809165, 'PRESCRIPTION': 0.00011039964672113049}\n",
            "{'APPOINTMENTS': 0.00012099213551119177, 'ASK_A_DOCTOR': 0.00013964530093562352, 'JUNK': 0.07692307692307693, 'LAB': 0.00038550501156515033, 'MISCELLANEOUS': 0.00013719303059404582, 'PRESCRIPTION': 0.00022079929344226098}\n",
            "{'APPOINTMENTS': 0.00012099213551119177, 'ASK_A_DOCTOR': 0.00027929060187124703, 'JUNK': 0.07692307692307693, 'LAB': 0.00038550501156515033, 'MISCELLANEOUS': 0.00041157909178213747, 'PRESCRIPTION': 0.00011039964672113049}\n",
            "{'APPOINTMENTS': 0.00012099213551119177, 'ASK_A_DOCTOR': 0.00013964530093562352, 'JUNK': 0.07692307692307693, 'LAB': 0.00038550501156515033, 'MISCELLANEOUS': 0.00013719303059404582, 'PRESCRIPTION': 0.00011039964672113049}\n",
            "{'APPOINTMENTS': 0.00012099213551119177, 'ASK_A_DOCTOR': 0.00027929060187124703, 'JUNK': 0.07692307692307693, 'LAB': 0.00038550501156515033, 'MISCELLANEOUS': 0.00013719303059404582, 'PRESCRIPTION': 0.00011039964672113049}\n",
            "{'APPOINTMENTS': 0.00012099213551119177, 'ASK_A_DOCTOR': 0.00013964530093562352, 'JUNK': 0.07692307692307693, 'LAB': 0.00038550501156515033, 'MISCELLANEOUS': 0.00013719303059404582, 'PRESCRIPTION': 0.00011039964672113049}\n",
            "{'APPOINTMENTS': 0.00012099213551119177, 'ASK_A_DOCTOR': 0.00013964530093562352, 'JUNK': 0.07692307692307693, 'LAB': 0.00038550501156515033, 'MISCELLANEOUS': 0.00041157909178213747, 'PRESCRIPTION': 0.00011039964672113049}\n",
            "Classifying test data......\n",
            "{6941: {'APPOINTMENTS': 0.03508771929824561, 'ASK_A_DOCTOR': 0.07107945817623237, 'JUNK': 0.7692307692307693, 'LAB': 0.07016191210485737, 'MISCELLANEOUS': 0.15338180820414324, 'PRESCRIPTION': 0.029807904614705234}}\n",
            "[]\n",
            "[] []\n",
            "Evaluating results.....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMgAmY0uJ4uz",
        "colab_type": "code",
        "outputId": "0438e1c3-e8ac-4094-b8be-841cc1d0eaa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        }
      },
      "source": [
        "features = [\"SUMMARY\", \"categories\", \"sub_categories\"]\n",
        "\n",
        "print(\"Loading data.....\")\n",
        "dataset = load_file(dataPath)\n",
        "data, target = dataset[features[0]].fillna(\" \"), dataset[features[1]]\n",
        "#print(classProbs)\n",
        "\n",
        "print(\"preprocessing data.....\")\n",
        "word_vectors = preprocess(data)\n",
        "trainInd, testInd = train_test_split(range(dataset.shape[0]), test_size=0.4, random_state=43)\n",
        "print(len(trainInd), len(testInd), dataset.shape)\n",
        "\n",
        "#print(trainingX.shape,testX.shape,trainingY.shape,testY.shape)\n",
        "print(\"Learning model.....\")\n",
        "model = learn_model(trainInd, dataset)\n",
        "\n",
        "print(\"Classifying test data......\")      \n",
        "#predictedY = classify(model, testX)\n",
        "\n",
        "print(\"Evaluating results.....\")\n",
        "#evaluate(testY,predictedY)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data.....\n",
            "preprocessing data.....\n",
            "34368 22912 (57280, 3)\n",
            "Learning model.....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0ab59b1cbd8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#print(trainingX.shape,testX.shape,trainingY.shape,testY.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Learning model.....\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainInd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classifying test data......\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-e35b17cb2b85>\u001b[0m in \u001b[0;36mlearn_model\u001b[0;34m(data, target)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlearn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#Your custom implementation of NaiveBayes classifier will go here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mclassCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-eJf1I0c_UE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}